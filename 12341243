[11/26/2025-15:06:52] [W] [TRT] onnx2trt_utils.cpp:366: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[11/26/2025-15:06:52] [E] Error[3]: model.backbone.11.block.2.fc1.bias_DequantizeLinear_dequantize_scale_node: only activation types allowed as input to this layer.
[11/26/2025-15:06:52] [E] [TRT] ModelImporter.cpp:773: While parsing node number 16 [DequantizeLinear -> "model.backbone.11.block.2.fc1.bias"]:
[11/26/2025-15:06:52] [E] [TRT] ModelImporter.cpp:774: --- Begin node ---
[11/26/2025-15:06:52] [E] [TRT] ModelImporter.cpp:775: input: "model.backbone.11.block.2.fc1.bias_quantized"
input: "model.backbone.11.block.2.fc1.bias_quantized_scale"
input: "model.backbone.11.block.2.fc1.bias_quantized_zero_point"
output: "model.backbone.11.block.2.fc1.bias"
name: "model.backbone.11.block.2.fc1.bias_DequantizeLinear"
op_type: "DequantizeLinear"

[11/26/2025-15:06:52] [E] [TRT] ModelImporter.cpp:776: --- End node ---
[11/26/2025-15:06:52] [E] [TRT] ModelImporter.cpp:779: ERROR: ModelImporter.cpp:179 In function parseGraph:
[6] Invalid Node - model.backbone.11.block.2.fc1.bias_DequantizeLinear
model.backbone.11.block.2.fc1.bias_DequantizeLinear_dequantize_scale_node: only activation types allowed as input to this layer.
[11/26/2025-15:06:52] [E] Failed to parse onnx file
[11/26/2025-15:06:52] [I] Finish parsing network model
[11/26/2025-15:06:52] [E] Parsing model failed
[11/26/2025-15:06:52] [E] Failed to create engine from model.
[11/26/2025-15:06:52] [E] Engine set up failed
&&&& FAILED TensorRT.trtexec [TensorRT v8201] # trtexec --onnx=model_quant.onnx --saveEngine=model.trt --int8
